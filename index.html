<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="TiDAR: Think in Diffusion, Talk in Autoregression">
  <meta property="og:title" content="TiDAR: Think in Diffusion, Talk in Autoregression"/>
  <meta property="og:description" content="TiDAR: Think in Diffusion, Talk in Autoregression"/>
  <!-- <meta property="og:url" content="https://research.nvidia.com/labs/lpr/dler_rl/"/> -->
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TiDAR: Think in Diffusion, Talk in Autoregression">
  <meta name="twitter:description" content="TiDAR: Think in Diffusion, Talk in Autoregression">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>TiDAR: Think in Diffusion, Talk in Autoregression</title>
  <link rel="icon" type="image/x-icon" href="https://www.nvidia.com/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.4/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  <script src="https://d3js.org/d3.v7.min.js"></script>
  
  <!-- MathJax for LaTeX rendering -->
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']],
        processEscapes: true,
        processEnvironments: true
      },
      options: {
        skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
      }
    };
  </script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.3/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">

  <script src="https://d3js.org/d3.v7.min.js"></script>
  <script src="https://d3js.org/d3.v7.min.js"></script>
  <script src="https://unpkg.com/d3-sankey@0.12.3/dist/d3-sankey.min.js"></script>
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
  <script src="document_samples.js"></script>
<!-- OneTrust Cookies Consent Notice start for nvidia.com -->
<!-- <script src="https://cdn.cookielaw.org/scripttemplates/otSDKStub.js" data-document-language="true" type="text/javascript" charset="UTF-8" data-domain-script="3e2b62ff-7ae7-4ac5-87c8-d5949ecafff5" ></script>
<script type="text/javascript">
function OptanonWrapper() {       
        var event = new Event('bannerLoaded');
        window.dispatchEvent(event);
    }
</script> -->
<!-- OneTrust Cookies Consent Notice end for nvidia.com -->
<!-- <script type="text/javascript" src="https://images.nvidia.com/aem-dam/Solutions/ot-js/ot-custom.js"></script> -->

<style>
  .policy-links {
    margin-top: 2rem;
    font-size: 0.9rem;
    line-height: 1.8;
  }
  
  .policy-link {
    color: #4a4a4a;
    padding: 0.2rem 0.5rem;
    transition: color 0.3s, background-color 0.3s;
    border-radius: 4px;
  }
  
  .policy-link:hover {
    color: #3273dc;
    background-color: #f5f5f5;
    text-decoration: none;
  }
  
  .separator {
    margin: 0 0.2rem;
    color: #dbdbdb;
  }
  
  @media screen and (max-width: 768px) {
    .policy-links {
      display: flex;
      flex-wrap: wrap;
      justify-content: center;
    }
    
    .policy-link {
      margin: 0.3rem;
    }
    
    .separator {
      display: none;
    }
  }
  
  /* Add these custom styles to your existing styles */
  .container.is-fullwidth {
    max-width: 100%;
    width: 100%;
    padding: 0 1rem;
  }
  
  .content figure.image img.large-diagram {
    width: 100%;
    max-height: 500px;
    object-fit: contain;
  }
  
  .results-table-container {
    overflow-x: auto;
    max-width: 100%;
    width: 100%;
    margin: 0;
    padding: 0;
  }
  
  .table-wrapper {
    padding: 0;
  }
  
  .compact-table {
    font-size: 0.75rem !important;
    width: 100%;
  }
  
  .compact-table th, 
  .compact-table td {
    padding: 0.4em 0.5em !important;
    white-space: nowrap;
  }

  .compact-table strong {
    font-weight: 700;
    color: #209cee;
  }
  
  @media screen and (max-width: 1023px) {
    .results-table-container {
      margin-left: -1rem;
      margin-right: -1rem;
      width: calc(100% + 2rem);
    }
  }
  
  @media screen and (min-width: 1024px) {
    .container.is-fullwidth {
      padding: 0 2rem;
    }
  }

  /* Extend the width of the Pre-training from Scratch section too */
  .container.is-wider {
    max-width: 1344px;
    margin: 0 auto;
  }

  /* ‰øÆÊîπÂõæÁâáËØ¥ÊòéÊñáÂ≠óÊ†∑ÂºèÔºöÂçïË°åÂ±Ö‰∏≠ÔºåÂ§öË°åÂ∑¶ÂØπÈΩê */
  figure.image figcaption {
    margin-top: 0.75rem;
    line-height: 1.4;
    color: #4a4a4a;
    font-size: 0.9rem;
    padding: 0 0.5rem;
    text-align: left; /* ÈªòËÆ§Â∑¶ÂØπÈΩê */
    max-width: 100%;
  }
  
  /* ÂçïË°åÊñáÊú¨Â±Ö‰∏≠ÁöÑÊäÄÂ∑ß */
  figure.image figcaption:not(:has(br)):not([style*="height"])[style*="display: -webkit-box;"] {
    text-align: center;
  }
  
  /* ÁÆÄÂçïÊõø‰ª£ÊñπÊ°àÔºöÊ£ÄÊµãÁü≠ÊñáÊú¨Âπ∂Â±Ö‰∏≠ */
  figure.image figcaption:not(:has(br)):not([style*="height"]) {
    text-align: center;
  }
  
  /* Ë°®Ê†ºÊ†áÈ¢ò‰ΩøÁî®Áõ∏ÂêåÁöÑÊ†∑ÂºèÈÄªËæë */
  table caption {
    margin-bottom: 1rem;
    color: #4a4a4a;
    font-weight: bold;
    text-align: left;
  }
  
  /* ÂçïË°åË°®Ê†ºÊ†áÈ¢òÂ±Ö‰∏≠ */
  table caption:not(:has(br)):not([style*="height"]) {
    text-align: center;
  }
</style>
  
<script>
  /* ‰∏∫Â§ÑÁêÜ‰∏çÂêåÊµèËßàÂô®ÂÖºÂÆπÊÄßÁöÑJavaScriptÂáΩÊï∞ */
  window.addEventListener('DOMContentLoaded', function() {
    // Â§ÑÁêÜÂõæÁâáËØ¥Êòé
    document.querySelectorAll('figure.image figcaption').forEach(function(caption) {
      // Â¶ÇÊûúÊñáÊú¨Ê≤°ÊúâÊç¢Ë°å‰∏îÂÆΩÂ∫¶‰∏çË∂ÖËøá‰∏ÄÂÆöÊØî‰æãÔºåËÆ§‰∏∫ÊòØÂçïË°åÊñáÊú¨
      if (caption.offsetHeight < 24 && caption.textContent.length < 100) {
        caption.style.textAlign = 'center';
      } else {
        caption.style.textAlign = 'left';
      }
    });
    
    // Â§ÑÁêÜË°®Ê†ºÊ†áÈ¢ò
    document.querySelectorAll('table caption').forEach(function(caption) {
      if (caption.offsetHeight < 24 && caption.textContent.length < 100) {
        caption.style.textAlign = 'center';
      } else {
        caption.style.textAlign = 'left';
      }
    });
  });
</script>

</head>
<body>

  <section class="hero" style="margin-bottom: -30px;">
    <div class="hero-body" style="padding: 1rem 1.5rem;">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title" style="margin-bottom: 0.5rem;">
              <!-- <img src="./static/images/climb.png" alt="DLER" style="height: 1.2em; vertical-align: middle; margin-right: 0.3em; display: inline-block;"> -->
              TiDAR: Think in Diffusion, Talk in Autoregression
            </h1>
            <div class="is-size-5 publication-authors" style="margin-bottom: 0.5rem;">
              <!-- Paper authors -->
                <span class="author-block">
                  <a href="https://jingyu6.github.io/" target="_blank">Jingyu Liu<sup>1*</sup></a>,</span>
                <span class="author-block">
                  <a href="https://simonxin.com/" target="_blank">Xin Dong<sup>*</sup></a>,</span>
                <span class="author-block">
                  <a href="https://scholar.google.com/citations?user=zlPfnWEAAAAJ&hl=en/" target="_blank">Zhifan Ye<sup>2</sup></a>,</span>
                <span class="author-block">
                  <a href="https://scholar.google.fr/citations?user=ZOH7UJAAAAAJ&hl=ro" target="_blank">Rishabh Mehta</a>,</span>
                <span class="author-block">
                  <a href="https://www.yongganfu.com/" target="_blank">Yonggan Fu</a>,</span>
                <span class="author-block">
                  <a href="https://www.linkedin.com/in/vartika-singh-554903a/" target="_blank">Vartika Singh</a>,</span>
                <span class="author-block">
                  <a href="https://jankautz.com/" target="_blank">Jan Kautz</a>,</span>  
                <span class="author-block">
                  <a href="https://zhangce.github.io/" target="_blank">Ce Zhang<sup>1</sup></a>,</span>                              
                <span class="author-block">
                  <a href="https://www.pmolchanov.com/" target="_blank">Pavlo Molchanov</a></span>
                </div>

                <div class="is-size-5 publication-authors" style="margin-bottom: 0.5rem;">
                  <span class="eql-cntrb"><small><sup>*</sup> Equal Contribution, XD as the Project Lead</small></span><br>
                  <span class="eql-cntrb"><small><br></small></span>
                  <span class="author-block">
                    <img src="https://www.nvidia.com/favicon.ico" alt="NVIDIA" style="width: 2em; height: 2em; vertical-align: middle; margin-right: 0.3em;">
                    NVIDIA
                  </span>
                    <span class="eql-cntrb"><small><br><sup>1</sup> affiliated with Univerisity of Chicago. Work done during Jingyu's internship at NVIDIA </small></span>
                    <span class="eql-cntrb"><small><br><sup>2</sup> affiliated with Georgia Institute of Technology. Work done during Zhifan's internship at NVIDIA </small></span>
                    <span class="eql-cntrb"><small><br><strong>(SGLang inference code will be released soon)</strong></small></span>
                  </div>

                <div class="column has-text-centered" style="margin-bottom: 0;">
                  <div class="publication-links">
                  <!-- Arxiv PDF link -->
                  <span class="link-block">
                  <a href="https://arxiv.org/abs/2511.08923v1" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- <span class="link-block">
                      <a href="https://huggingface.co/collections/nvidia/reasoning-efficiency-research" target="_blank" class="external-link button is-normal is-rounded is-dark">
                        <span class="icon" style="font-size:18px">ü§ó</span>
                        <span>Models</span>
                      </a>
                    </span> -->
                    <!-- <span class="link-block">
                        <a href="https://huggingface.co/datasets/nvidia/ClimbMix" class="external-link button is-normal is-rounded is-dark">
                          <span class="icon" style="font-size:18px"></span>
                          <span>Code</span>
                        </a>
                      </span> -->
                      <!-- <span class="link-block">
                        <a href="https://github.com/NVlabs/DLER" target="_blank" class="external-link button is-normal is-rounded is-dark">
                          <span class="icon" style="font-size:18px">
                            <i class="fab fa-github"></i>
                          </span>
                          <span>Code</span>
                        </a>
                      </span> -->

                    <!-- Supplementary PDF link -->
                    <!-- <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                  <!-- Github link -->
                  <!-- <span class="link-block">
                    <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span> -->

                <!-- ArXiv abstract Link -->
                <!-- <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                  </a>
                </span> -->

            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Generation Demo -->

<section class="section" style="padding: 2rem 1.5rem;">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column has-text-centered">
        <h2 class="title is-4 has-text-centered has-text-black" style="margin-bottom: 1.5rem;">
          TiDAR's Parallel Diffusion Drafting and Autoregressive Sampling
        </h2>
        <div class="image" style="padding: 0; overflow: hidden; top: -20px;">
          <img src="static/images/animation.gif" alt="TiDAR's Parallel Diffusion Drafting and Autoregressive Sampling">
        </div>
        <div class="content has-text-centered">
          (We illustrate with draft length = 3; TiDAR 1.5B and 8B use draft length = 16 in practice.)
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Interactive Streaming Demo Section -->
<section class="section" style="padding: 2rem 1.5rem; background: linear-gradient(135deg, #ffffff 0%, #ffffff 100%);">
  <div class="container is-fluid">
    <div class="columns is-centered">
      <div class="column">
        <h2 class="title is-4 has-text-centered has-text-black" style="margin-bottom: 1.5rem;">
          Model Response Examples
        </h2>
        
        <!-- Question Selector -->
        <div class="field">
          <label class="label has-text-black">Select a Question:</label>
          <div class="control">
            <div class="select is-fullwidth is-medium">
              <select id="questionSelect">
              </select>
            </div>
          </div>
        </div>

          

        <!-- Time Scaling Factor Slider -->
        <div class="field" style="margin-top: 1rem;">
          <label class="label has-text-black">
            Display Speed: <span id="timeScalingValue">1.0<span class="multiplier">x</span></span>  (drag to slow down)
          </label>
          <div class="control">
            <input 
              type="range" 
              id="timeScalingSlider" 
              class="slider" 
              min="0.1" 
              max="1.0" 
              step="0.1" 
              value="1.0"
              style="width: 50%;"
            >
            <!-- <div class="help has-text-grey" style="margin-top: 0.25rem;">
              Adjust the time scaling factor to control animation speed (lower = faster, higher = slower)
            </div> -->
          </div>
        </div>

        <!-- Question Display -->
        <div id="questionDisplay" class="box" style="display: none; margin-top: 1.5rem; background-color: rgba(255,255,255,0.95); border-radius: 8px; padding: 0.75rem;">
          <h3 class="title is-5" style="color: #363636; margin-bottom: 1rem;">Question:</h3>
          <p id="questionText" style="font-size: 1.1rem; color: #4a4a4a; margin-bottom: 1.5rem; white-space: pre-wrap;"></p>


          <!-- Models Comparison -->
          <div class="columns is-variable is-1">
            <!-- Model A -->
            <div class="column is-half" style="padding: 0.25rem;">
              <div class="box" style="background-color: #e8fff0; min-height: 400px; position: relative; padding: 0.5rem;">
                <h4 id="modelAName" class="title is-5" style="margin-bottom: 0.5rem; color: #2e7d32;">Model A</h4>
                <div class="model-stats" style="margin-bottom: 1rem;">
                  <div class="tags">
                    <span class="tag is-light is-medium">
                      <span class="icon"><i class="fas fa-clock"></i></span>
                      <span>Time: <strong id="modelATime">0.0s</strong></span>
                    </span>
                    <span class="tag is-light is-medium">
                      <span class="icon"><i class="fas fa-coins"></i></span>
                      <span>Tokens: <strong id="modelATokens">0</strong></span>
                    </span>
                  </div>
                </div>
                <div id="modelAOutput" class="content" style="background-color: rgba(0,0,0,0.05); color: #1b5e20; padding: 0.5rem; border-radius: 6px; min-height: 250px; max-height: 250px; overflow-y: auto; overflow-x: hidden; font-size: 0.95rem; line-height: 1.6; word-wrap: break-word; overflow-wrap: break-word; word-break: break-word; white-space: pre-wrap;"></div>
              </div>
            </div>

            <!-- Model B -->
            <div class="column is-half" style="padding: 0.25rem;">
              <div class="box" style="background-color: #f6e8ff; min-height: 400px; position: relative; padding: 0.5rem;">
                <h4 id="modelBName" class="title is-5" style="margin-bottom: 0.5rem; color: #6a1b9a;">Model B</h4>
                <div class="model-stats" style="margin-bottom: 1rem;">
                  <div class="tags">
                    <span class="tag is-light is-medium">
                      <span class="icon"><i class="fas fa-clock"></i></span>
                      <span>Time: <strong id="modelBTime">0.0s</strong></span>
                    </span>
                    <span class="tag is-light is-medium">
                      <span class="icon"><i class="fas fa-coins"></i></span>
                      <span>Tokens: <strong id="modelBTokens">0</strong></span>
                    </span>
                  </div>
                </div>
                <div id="modelBOutput" class="content" style="background-color: rgba(0,0,0,0.05); color: #4a148c; padding: 0.5rem; border-radius: 6px; min-height: 250px; max-height: 250px; overflow-y: auto; overflow-x: hidden; font-size: 0.95rem; line-height: 1.6; word-wrap: break-word; overflow-wrap: break-word; word-break: break-word; white-space: pre-wrap;"></div>
              </div>
            </div>
          </div>

          <!-- Control Buttons -->
          <div class="field is-grouped is-grouped-centered" style="margin-top: 1rem;">
            <p class="control">
              <button id="startButton" class="button is-primary is-small" disabled>
                <span class="icon is-small"><i class="fas fa-play"></i></span>
                <span>Start</span>
              </button>
            </p>
            <div class="field has-addons" style="margin-left: 1rem;">
              <p class="control">
                <button id="manual-control-button" class="button is-info is-small" disabled>
                  <span class="icon is-small"><i class="fas fa-cogs"></i></span>
                  <span>Manual</span>
                </button>
              </p>
              <p class="control">
                <button id="prev-step-button" class="button is-small" disabled>
                  <span class="icon is-small"><i class="fas fa-chevron-left"></i></span>
                </button>
              </p>
              <p class="control">
                <button id="next-step-button" class="button is-small" disabled>
                  <span class="icon is-small"><i class="fas fa-chevron-right"></i></span>
                </button>
              </p>
            </div>
          </div>

          <!-- Efficiency Summary -->
          <div id="efficiencySummary" class="notification is-success is-light" style="display: none; margin-top: 0.75rem; padding: 0.75rem 1rem;">
            <p class="has-text-centered" style="margin: 0; font-size: 1.1rem;">
              <span id="efficiencyText"></span>
            </p>
          </div>

          <p class="has-text-centered" style="margin-top: 0.5rem; font-size: 0.85rem; color: #6b7280;">
            * As base models, both models exhibit a common behavior: they continue generating even after completing a response to the current question. For a fair comparison of their generation speeds, we truncated the output at a length of 512 tokens.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<style>
  #modelAOutput, #modelBOutput {
    scrollbar-width: thin;
    scrollbar-color: rgba(255,255,255,0.5) transparent;
  }
  
  #modelAOutput::-webkit-scrollbar, #modelBOutput::-webkit-scrollbar {
    width: 8px;
  }
  
  #modelAOutput::-webkit-scrollbar-track, #modelBOutput::-webkit-scrollbar-track {
    background: transparent;
  }
  
  #modelAOutput::-webkit-scrollbar-thumb, #modelBOutput::-webkit-scrollbar-thumb {
    background-color: rgba(255,255,255,0.5);
    border-radius: 4px;
  }

  .model-stats .tags {
    display: flex;
    gap: 0.5rem;
    flex-wrap: wrap;
  }

  /* Prevent overflow in the Interactive Streaming Demo section */
  #questionDisplay .columns {
    max-width: 100%;
  }
  
  #questionDisplay .column {
    max-width: 100%;
    overflow: hidden;
  }
  
  #questionDisplay .box {
    max-width: 100%;
    overflow: hidden;
  }

  /* Style for model name links */
  #modelAName a, #modelBName a {
    transition: opacity 0.2s ease;
  }
  
  #modelAName a:hover, #modelBName a:hover {
    opacity: 0.8;
  }
  
  .last-words-color {
    color: #ffd54f;
    background-color: rgba(255, 213, 79, 0.15);
    padding: 2px 4px;
    border-radius: 3px;
    text-decoration: underline;
    text-decoration-color: #ffd54f;
    text-decoration-thickness: 2px;
    text-underline-offset: 2px;
  }

  /* Time scaling slider styles */
  #timeScalingSlider {
    -webkit-appearance: none;
    appearance: none;
    height: 8px;
    border-radius: 4px;
    background: #dbdbdb;
    outline: none;
    transition: background 0.3s;
  }

  #timeScalingSlider:hover {
    background: #c0c0c0;
  }

  #timeScalingSlider::-webkit-slider-thumb {
    -webkit-appearance: none;
    appearance: none;
    width: 20px;
    height: 20px;
    border-radius: 50%;
    background: #3273dc;
    cursor: pointer;
    transition: background 0.3s, transform 0.2s;
  }

  #timeScalingSlider::-webkit-slider-thumb:hover {
    background: #2366d1;
    transform: scale(1.1);
  }

  #timeScalingSlider::-moz-range-thumb {
    width: 20px;
    height: 20px;
    border-radius: 50%;
    background: #3273dc;
    cursor: pointer;
    border: none;
    transition: background 0.3s, transform 0.2s;
  }

  #timeScalingSlider::-moz-range-thumb:hover {
    background: #2366d1;
    transform: scale(1.1);
  }

  #timeScalingValue {
    font-weight: bold;
    color: #3273dc;
    font-size: 1.1em;
  }

  #timeScalingValue .multiplier {
    font-size: 0.85em;
    opacity: 0.8;
    margin-left: 1px;
  }
</style>

<script>
  let streamingData = [];
  let currentQuestion = null;
  let isStreaming = false;
  let streamingIntervalA = null;
  let streamingIntervalB = null;
  let speculation_data = [];
    let time_scaling_factor = 1.0; // Default time scaling factor
  let isManualMode = false;
  let currentStepA = 0;
  let currentStepB = 0;

  // Load streaming data
  fetch('streaming_data_neo.json')
    .then(response => response.json())
    .then(data => {
      streamingData = data;
      populateQuestions();
    })
    .catch(error => console.error('Error loading streaming data:', error));

  // fetch('decoding_progress_gsm8k_cot.json')
  //   .then(response => response.json())
  //   .then(data => {
  //     speculation_data = data;
  //   })
  //   .catch(error => console.error('Error loading decoding progress:', error));

  function populateQuestions() {
    const select = document.getElementById('questionSelect');
    streamingData.forEach(item => {
      const option = document.createElement('option');
      option.value = item.id;
      option.textContent = item.question;
      select.appendChild(option);
    });
    
    // Automatically select the first question
    if (streamingData.length > 0) {
      select.value = streamingData[0].id;
      currentQuestion = streamingData[0];
      displayQuestion();
      // Automatically start streaming after a short delay
      setTimeout(() => {
        if (currentQuestion && !isStreaming) {
          startStreaming();
        }
      }, 500);
    }
  }

  document.getElementById('questionSelect').addEventListener('change', function(e) {
    const questionId = parseInt(e.target.value);
    if (!isNaN(questionId)) {
      currentQuestion = streamingData.find(q => q.id === questionId);
      if (currentQuestion) {
                stopStreaming();
        isManualMode = false;
        document.getElementById('manual-control-button').classList.remove('is-active');
        document.getElementById('prev-step-button').disabled = true;
        document.getElementById('next-step-button').disabled = true;
        document.getElementById('startButton').disabled = false;
        displayQuestion();
        // Automatically start streaming for newly selected question
        setTimeout(() => {
          if (currentQuestion && !isStreaming) {
            startStreaming();
          }
        }, 300);
      }
    }
  });

  // Time scaling factor slider event listener
  // Ensure DOM is ready before setting up the slider
  function setupTimeScalingSlider() {
    const timeScalingSlider = document.getElementById('timeScalingSlider');
    const timeScalingValue = document.getElementById('timeScalingValue');
    
    if (timeScalingSlider && timeScalingValue) {
      timeScalingSlider.addEventListener('input', function(e) {
        time_scaling_factor = parseFloat(e.target.value);
        timeScalingValue.innerHTML = time_scaling_factor.toFixed(1) + '<span class="multiplier">x</span>';
        
        // If streaming is active, restart with new scaling factor
        if (isStreaming && currentQuestion) {
          stopStreaming();
          // Reset the display
          document.getElementById('modelAOutput').innerHTML = '';
          document.getElementById('modelBOutput').innerHTML = '';
          document.getElementById('modelATime').textContent = '0.0s';
          document.getElementById('modelBTime').textContent = '0.0s';
          document.getElementById('modelATokens').textContent = '0';
          document.getElementById('modelBTokens').textContent = '0';
          document.getElementById('efficiencySummary').style.display = 'none';
          // Restart streaming with new scaling factor
          setTimeout(() => {
            startStreaming();
          }, 100);
        }
      });
    }
  }
  
  // Setup slider when DOM is ready
  if (document.readyState === 'loading') {
    document.addEventListener('DOMContentLoaded', setupTimeScalingSlider);
  } else {
    setupTimeScalingSlider();
  }

  function displayQuestion() {
    document.getElementById('questionDisplay').style.display = 'block';
    
    // Render question text with math support
    const questionElement = document.getElementById('questionText');
    const formattedQuestion = escapeHtmlButPreserveMath(currentQuestion.actual_prompt).replace(/\n/g, '<br>');
    questionElement.innerHTML = formattedQuestion;
    
    // Trigger MathJax to render the math in question
    if (window.MathJax && window.MathJax.typesetPromise) {
      MathJax.typesetPromise([questionElement]).catch((err) => console.error('MathJax error:', err));
    }
    
    // Set model names with optional links
    const modelANameElement = document.getElementById('modelAName');
    const modelBNameElement = document.getElementById('modelBName');
    
    if (currentQuestion.model_a.link) {
      modelANameElement.innerHTML = `<a href="${currentQuestion.model_a.link}" target="_blank" rel="noopener noreferrer" style="color: inherit; text-decoration: underline; cursor: pointer; display: inline-flex; align-items: center; gap: 6px;"><span style="width: 1px; height: 32px; display: inline-block;"></span>${currentQuestion.model_a.name}</a>`;
    } else {
      modelANameElement.textContent = currentQuestion.model_a.name;
    }
    
    if (currentQuestion.model_b.link) {
      modelBNameElement.innerHTML = `<a href="${currentQuestion.model_b.link}" target="_blank" rel="noopener noreferrer" style="color: inherit; text-decoration: underline; cursor: pointer; display: inline-flex; align-items: center; gap: 6px;"><span style="width: 1px; height: 32px; display: inline-block;"></span>${currentQuestion.model_b.name}</a>`;
    } else {
      modelBNameElement.textContent = currentQuestion.model_b.name;
    }
    
    // Reset outputs and stats
    document.getElementById('modelAOutput').innerHTML = '';
    document.getElementById('modelBOutput').innerHTML = '';
    document.getElementById('modelATime').textContent = '0.0s';
    document.getElementById('modelBTime').textContent = '0.0s';
    document.getElementById('modelATokens').textContent = '0';
    document.getElementById('modelBTokens').textContent = '0';
    document.getElementById('efficiencySummary').style.display = 'none';
    
        document.getElementById('startButton').disabled = false;
    document.getElementById('manual-control-button').disabled = false;
  }

  document.getElementById('startButton').addEventListener('click', function() {
      if (currentQuestion) {
      isManualMode = false;
      document.getElementById('manual-control-button').classList.remove('is-active');
      document.getElementById('prev-step-button').disabled = true;
      document.getElementById('next-step-button').disabled = true;
      // Stop any ongoing streaming
      stopStreaming();
      // Reset the display
      document.getElementById('modelAOutput').innerHTML = '';
      document.getElementById('modelBOutput').innerHTML = '';
      document.getElementById('modelATime').textContent = '0.0s';
      document.getElementById('modelBTime').textContent = '0.0s';
      document.getElementById('modelATokens').textContent = '0';
      document.getElementById('modelBTokens').textContent = '0';
      document.getElementById('efficiencySummary').style.display = 'none';
      // Start streaming after a brief delay
      setTimeout(() => {
        startStreaming();
      }, 100);
    }
    });

  document.getElementById('manual-control-button').addEventListener('click', function() {
    if (currentQuestion) {
      isManualMode = !isManualMode;
      if (isManualMode) {
        stopStreaming();
        this.classList.add('is-active');
        document.getElementById('startButton').disabled = true;
        document.getElementById('prev-step-button').disabled = false;
        document.getElementById('next-step-button').disabled = false;
        currentStepA = 0;
        renderStep('A', 0);
        const modelB = currentQuestion.model_b;
        const outputB = document.getElementById('modelBOutput');
        const timeB = document.getElementById('modelBTime');
        const tokensB = document.getElementById('modelBTokens');
        const formattedB = escapeHtmlButPreserveMath(modelB.response).replace(/\n/g, '<br>');
        outputB.innerHTML = formattedB;
        if (window.MathJax && window.MathJax.typesetPromise) {
          MathJax.typesetPromise([outputB]).catch((err) => console.error('MathJax error:', err));
        }
        timeB.textContent = modelB.actual_stream_time.toFixed(1) + 's';
        tokensB.textContent = modelB.total_tokens;
        updateManualButtons();
      } else {
        this.classList.remove('is-active');
        document.getElementById('startButton').disabled = false;
        document.getElementById('prev-step-button').disabled = true;
        document.getElementById('next-step-button').disabled = true;
        stopStreaming();
        displayQuestion();
        setTimeout(() => {
          if (currentQuestion && !isStreaming) {
            startStreaming();
          }
        }, 100);
      }
    }
  });

  document.getElementById('next-step-button').addEventListener('click', function() {
    manualStep(1);
  });

  document.getElementById('prev-step-button').addEventListener('click', function() {
    manualStep(-1);
  });

    function startStreaming() {
    if (isManualMode) return;
    isStreaming = true;
    document.getElementById('efficiencySummary').style.display = 'none';

    // Parse the current time_scaling_factor from the slider
    const timeScalingSlider = document.getElementById('timeScalingSlider');
    const currentTimeScalingFactor = timeScalingSlider ? parseFloat(timeScalingSlider.value) : 1.0;

    const modelA = currentQuestion.model_a;
    const modelB = currentQuestion.model_b;

    // Calculate streaming parameters
    const maxAnimationTime = Math.max(modelA.animation_time, modelB.animation_time) / currentTimeScalingFactor;
    
    // streamModel(modelA, 'A', maxAnimationTime);
    streamSpeculativeModel(modelA, 'A', maxAnimationTime, currentTimeScalingFactor);
    streamModel(modelB, 'B', maxAnimationTime, currentTimeScalingFactor);
  }

  function escapeHtmlButPreserveMath(text) {
    // Split text by LaTeX delimiters to preserve math expressions
    const parts = [];
    let lastIndex = 0;
    const regex = /\\\(|\\\)|\\\[|\\\]/g;
    let match;
    let inMath = false;
    let mathStart = 0;
    
    while ((match = regex.exec(text)) !== null) {
      if (match[0] === '\\(' || match[0] === '\\[') {
        if (!inMath) {
          // Regular text before math
          const regularText = text.substring(lastIndex, match.index);
          parts.push(escapeHtml(regularText));
          mathStart = match.index;
          inMath = true;
        }
      } else if (match[0] === '\\)' || match[0] === '\\]') {
        if (inMath) {
          // Math expression including delimiters
          const mathExpr = text.substring(mathStart, match.index + match[0].length);
          parts.push(mathExpr);
          lastIndex = match.index + match[0].length;
          inMath = false;
        }
      }
    }
    
    // Add remaining text
    if (lastIndex < text.length) {
      parts.push(escapeHtml(text.substring(lastIndex)));
    }
    
    return parts.join('');
  }
  
  function escapeHtml(text) {
    const div = document.createElement('div');
    div.textContent = text;
    return div.innerHTML;
  }
  
  function formatAcceptedAndDraftText(acceptedText = '', draftText = '') {
    const acceptedHtml = escapeHtmlButPreserveMath(acceptedText).replace(/\n/g, '<br>');
    
    if (!draftText) {
      return acceptedHtml;
    }
    
    const draftHtml = escapeHtmlButPreserveMath(draftText).replace(/\n/g, '<br>');
    return `${acceptedHtml}<span class="last-words-color">${draftHtml}</span>`;
  }

  function streamModel(model, modelId, maxAnimationTime, currentTimeScalingFactor) {
    const response = model.response;
    const totalTokens = model.total_tokens;
    const animationTime = model.animation_time / currentTimeScalingFactor;
    const actualStreamTime = model.actual_stream_time;
    
    const outputElement = document.getElementById(`model${modelId}Output`);
    const timeElement = document.getElementById(`model${modelId}Time`);
    const tokensElement = document.getElementById(`model${modelId}Tokens`);
    
    const MAX_VISIBLE_CHARS = 800; // Maximum characters to display at once
    const FRAME_RATE = 60; // Updates per second
    const frameInterval = 1000 / FRAME_RATE;
    
    const startTime = Date.now();
    const endTime = startTime + (animationTime * 1000);
    
    const interval = setInterval(() => {
      const now = Date.now();
      const elapsed = now - startTime;
      const progress = Math.min(elapsed / (animationTime * 1000), 1);
      
      // Calculate current position in text - ensure we reach the full length
      const currentIndex = Math.floor(progress * response.length);
      
      if (progress < 1) {
        const fullText = response.substring(0, currentIndex);
        
        // If text exceeds max visible chars, show only the latest portion
        let displayText;
        if (fullText.length > MAX_VISIBLE_CHARS) {
          displayText = '...' + fullText.substring(fullText.length - MAX_VISIBLE_CHARS);
        } else {
          displayText = fullText;
        }
        
        // Convert line breaks to <br> and set innerHTML
        const formattedText = escapeHtmlButPreserveMath(displayText).replace(/\n/g, '<br>');
        outputElement.innerHTML = formattedText;
        
        // Auto-scroll to bottom
        outputElement.scrollTop = outputElement.scrollHeight;
        
        // Update stats - show proportional actual time based on progress
        const displayTime = actualStreamTime * progress;
        const displayTokens = Math.floor(totalTokens * progress);
        timeElement.textContent = displayTime.toFixed(1) + 's';
        tokensElement.textContent = displayTokens;
      } else {
        clearInterval(interval);
        
        // First, show the complete text without rendering (for smooth transition)
        const fullText = response;
        let displayText;
        if (fullText.length > MAX_VISIBLE_CHARS) {
          displayText = '...' + fullText.substring(fullText.length - MAX_VISIBLE_CHARS);
        } else {
          displayText = fullText;
        }
        const formattedText = escapeHtmlButPreserveMath(displayText).replace(/\n/g, '<br>');
        outputElement.innerHTML = formattedText;
        outputElement.scrollTop = outputElement.scrollHeight;
        
        // Update final stats
        timeElement.textContent = actualStreamTime.toFixed(1) + 's';
        tokensElement.textContent = totalTokens;
        
        // Add a small delay before MathJax rendering for smooth transition
        setTimeout(() => {
          // Show full text for MathJax rendering
          const formattedResponse = escapeHtmlButPreserveMath(response).replace(/\n/g, '<br>');
          outputElement.innerHTML = formattedResponse;
          
          // Trigger MathJax to render the math
          if (window.MathJax && window.MathJax.typesetPromise) {
            MathJax.typesetPromise([outputElement]).catch((err) => console.error('MathJax error:', err));
          }
          
          outputElement.scrollTop = outputElement.scrollHeight;
          
          // Check if both models finished
          checkBothFinished();
        }, 200); // Small delay for smooth transition
      }
    }, frameInterval);
    
    if (modelId === 'A') {
      streamingIntervalA = interval;
    } else {
      streamingIntervalB = interval;
    }
  }

  // stream the speculative decoding progress
  function streamSpeculativeModel(model, modelId, maxAnimationTime, currentTimeScalingFactor) {
    const response = model.response;
    const totalTokens = model.total_tokens;
    const animationTime = model.animation_time / currentTimeScalingFactor;
    const actualStreamTime = model.actual_stream_time;
    const decoding_progress = model.speculative_progress;


    const outputElement = document.getElementById(`model${modelId}Output`);
    const timeElement = document.getElementById(`model${modelId}Time`);
    const tokensElement = document.getElementById(`model${modelId}Tokens`);
    
    const MAX_VISIBLE_CHARS = 800; // Maximum characters to display at once
    const FRAME_RATE = 60; // Updates per second
    const frameInterval = 1000 / FRAME_RATE;
    
    const startTime = Date.now();
    const endTime = startTime + (animationTime * 1000);
    
    const interval = setInterval(() => {
      const now = Date.now();
      const elapsed = now - startTime;
      const progress = Math.min(elapsed / (animationTime * 1000), 1);
      
      // Calculate current position in text - ensure we reach the full length
      const currentIndex = Math.floor(progress * decoding_progress.length);
      
      if (progress < 1) {
        const acceptedText = decoding_progress[currentIndex][0];
        const draftText = decoding_progress[currentIndex][1];
        const decodedTokens = decoding_progress[currentIndex][2];
        
        // Convert line breaks to <br>, append draft tail, and set innerHTML
        const formattedText = formatAcceptedAndDraftText(acceptedText, draftText);
        outputElement.innerHTML = formattedText;
        
        // Auto-scroll to bottom
        outputElement.scrollTop = outputElement.scrollHeight;
        
        // Update stats - show proportional actual time based on progress
        const displayTime = actualStreamTime * progress;
        const displayTokens = Math.floor(totalTokens * progress);
        timeElement.textContent = displayTime.toFixed(1) + 's';
        tokensElement.textContent = decodedTokens;
      } else {
        clearInterval(interval);
        
        // First, show the complete text without rendering (for smooth transition)
        const fullText = response;
        let displayText;
        if (fullText.length > MAX_VISIBLE_CHARS) {
          displayText = '...' + fullText.substring(fullText.length - MAX_VISIBLE_CHARS);
        } else {
          displayText = fullText;
        }
        const formattedText = escapeHtmlButPreserveMath(displayText).replace(/\n/g, '<br>');
        outputElement.innerHTML = formattedText;
        outputElement.scrollTop = outputElement.scrollHeight;
        
        // Update final stats
        timeElement.textContent = actualStreamTime.toFixed(1) + 's';
        tokensElement.textContent = totalTokens;
        
        // Add a small delay before MathJax rendering for smooth transition
        setTimeout(() => {
          // Show full text for MathJax rendering
          const formattedResponse = escapeHtmlButPreserveMath(response).replace(/\n/g, '<br>');
          outputElement.innerHTML = formattedResponse;
          
          // Trigger MathJax to render the math
          if (window.MathJax && window.MathJax.typesetPromise) {
            MathJax.typesetPromise([outputElement]).catch((err) => console.error('MathJax error:', err));
          }
          
          outputElement.scrollTop = outputElement.scrollHeight;
          
          // Check if both models finished
          checkBothFinished();
        }, 200); // Small delay for smooth transition
      }
    }, frameInterval);
    
    if (modelId === 'A') {
      streamingIntervalA = interval;
    } else {
      streamingIntervalB = interval;
    }
  }

    function checkBothFinished() {
    if (isManualMode) {
      const modelA = currentQuestion.model_a;
      const modelAComplete = currentStepA >= modelA.speculative_progress.length - 1;
      if (modelAComplete) {
        showEfficiencySummary();
      }
    } else {
      const modelAText = document.getElementById('modelAOutput').textContent;
      const modelBText = document.getElementById('modelBOutput').textContent;
      
      const modelAComplete = modelAText.length >= currentQuestion.model_a.response.length - 5;
      const modelBComplete = modelBText.length >= currentQuestion.model_b.response.length - 5;
      
      if (modelAComplete && modelBComplete) {
        isStreaming = false;
        showEfficiencySummary();
      }
    }
  }

  function showEfficiencySummary() {
    console.log('Current question:', currentQuestion);
    console.log('Efficiency text:', currentQuestion.efficiency_text);
    
    const efficiencyText = currentQuestion.efficiency_text || '';
    document.getElementById('efficiencyText').textContent = efficiencyText;
    document.getElementById('efficiencySummary').style.display = 'block';
  }

    function renderStep(modelId, step) {
    const model = modelId === 'A' ? currentQuestion.model_a : currentQuestion.model_b;
    const outputElement = document.getElementById(`model${modelId}Output`);
    const timeElement = document.getElementById(`model${modelId}Time`);
    const tokensElement = document.getElementById(`model${modelId}Tokens`);

    if (modelId === 'A') {
      const decoding_progress = model.speculative_progress;
      if (step >= 0 && step < decoding_progress.length) {
        const [acceptedText, draftText, decodedTokens] = decoding_progress[step];
        const formattedText = formatAcceptedAndDraftText(acceptedText, draftText);
        outputElement.innerHTML = formattedText;
        tokensElement.textContent = decodedTokens;
        const progress = (step + 1) / decoding_progress.length;
        const displayTime = model.actual_stream_time * progress;
        timeElement.textContent = displayTime.toFixed(1) + 's';
      }
    } else { // Model B
      const response = model.response;
      if (step >= 0 && step < response.length) {
        const displayText = response.substring(0, step + 1);
        const formattedText = escapeHtmlButPreserveMath(displayText).replace(/\n/g, '<br>');
        outputElement.innerHTML = formattedText;

        const progress = (step + 1) / response.length;
        const displayTokens = Math.floor(model.total_tokens * progress);
        tokensElement.textContent = displayTokens;
        const displayTime = model.actual_stream_time * progress;
        timeElement.textContent = displayTime.toFixed(1) + 's';
      }
    }
    outputElement.scrollTop = outputElement.scrollHeight;
  }

  function manualStep(direction) {
    if (!isManualMode || !currentQuestion) return;

    const modelA = currentQuestion.model_a;

    let nextStepA = currentStepA + direction;
    if (nextStepA >= 0 && nextStepA < modelA.speculative_progress.length) {
      currentStepA = nextStepA;
    }

    renderStep('A', currentStepA);

    updateManualButtons();
    checkBothFinished();
  }

  function updateManualButtons() {
    if (!isManualMode || !currentQuestion) return;

    const modelA = currentQuestion.model_a;

    const canGoPrev = currentStepA > 0;
    const canGoNext = currentStepA < modelA.speculative_progress.length - 1;

    document.getElementById('prev-step-button').disabled = !canGoPrev;
    document.getElementById('next-step-button').disabled = !canGoNext;
  }

  function stopStreaming() {
    if (streamingIntervalA) {
      clearInterval(streamingIntervalA);
      streamingIntervalA = null;
    }
    if (streamingIntervalB) {
      clearInterval(streamingIntervalB);
      streamingIntervalB = null;
    }
    isStreaming = false;
  }
</script>

<!-- Paper abstract -->
<section class="section hero is-light" style="padding: 1rem 1.5rem; margin-top: 0px;">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3" style="margin-bottom: 0.75rem;">What is the project about?</h2>
        <div class="content has-text-justified">
          <ul>
            <li>
            Diffusion language models hold the promise of fast parallel generation, while autoregressive (AR) models typically excel in quality. But why choose? 
            TiDAR allows you have the best of both worlds in one model with zero overhead by leveraging the unused compute to memory density on GPUs.
            </li>
            <li>
            We introduce <strong>TiDAR, a sequence-level hybrid architecture that drafts tokens (Thinking) in Diffusion and samples final outputs (Talking) in AutoRegression - all within a single forward pass using a structured attention mask.</strong>
            </li>
            <li>
            We extensively evaluate TiDAR against AR models, speculative decoding, and diffusion variants across generative and likelihood tasks at 1.5B and 8B scales. Thanks to the parallel drafting and sampling as well as exact KV cache support, TiDAR outperforms speculative decoding in measured throughput and surpasses diffusion models like Dream and Llada in both efficiency and quality. Most notably, TiDAR is the first architecture to close the quality gap with AR models while delivering 4.71x to 5.91x more tokens per second.
            </li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Overview Section -->
<section class="section" style="padding-top: 1rem; padding-bottom: 1rem;">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column">
        <!-- <h2 class="title is-3" style="margin-bottom: 0.75rem;">Leverage the "free GPU compute" to achieve AR and diffusion synergy</h2> -->
        <div class="content">
          <h3 class="title is-4" style="margin-bottom: 0.75rem; color:forestgreen;">The Secret Sauce: Free Token Slots</h3></li>
          <figure class="image">
            <img src="static/images/latency_scaling_32b.png" style="width: 40%; height: auto;" alt="Free Token Slots">
            <figcaption>Figure 1: Free Token Slots</figcaption>
          </figure>
          <div class="content has-text-justified mt-4">
            <p>
            The power of modern GPUs gets fully utilized under a balanced load between compute density and memory IO. Increasing batch size can increase the compute density by reusing the model weights, but this requires loading more KV cache for each sample and more aggressive model sharding. 
            <!-- For situations where we care more about per-request latency, w -->
            It turns out that passing a decent amount of extra tokens to the forward results in similar latency. 
            Under the context of TiDAR, we append sets of mask tokens to perform diffusion pre-drafting and also verifiying tokens from last step to conduct autoregressive sampling.  
            <!-- Diffusion models can speedup generation exactly from this perspective and we take the extreme route by diffusing multiple sets of proposals.  -->
            When the draft length is chosen wisely, computing these extra tokens in parallel does not introduce extra latency, and therefore, we refer to these as "free token slots".
            </p>
          </div>
        </div>

        <div class="content">
          <h3 class="title is-4" style="margin-bottom: 0.75rem; color:forestgreen;">Sequence-level Hybrid Attention</h3></li>
          <figure class="image">
            <img src="static/images/mask.png" style="width: 80%; height: auto;" alt="Sequence-level Hybrid Attention">
            <figcaption>Figure 2: Sequence-level Hybrid Attention Patterns</figcaption>
          </figure>
          <br>
          <div class="content has-text-justified">
            <p>
            We conduct parallel diffusion drafting and autoregressive sampling in a single forward pass with a structured attention mask. In TiDAR, the prefix tokens and tokens from the last step that are waiting to be verified are attended causally, while the draft tokens are attended in a bidirectional manner. 
            </p>
          </div>
        </div>

        <div class="content">
          <h3 class="title is-4" style="margin-bottom: 0.75rem; color:forestgreen;">Diffusion Self-Speculation with Autoregressive Verification</h3></li>
          <figure class="image">
            <img src="static/images/comparison.png" style="width: 50%; height: auto;" alt="Comparison of TiDAR with Related Works">
            <figcaption>Figure 3: Comparing TiDAR with other frameworks.</figcaption>
          </figure>
          <div class="content has-text-justified mt-4">
            <p>
            With the help of the customized structured mask, we can verify the proposals from last step as well as pre-draft new proposals starting at every single prefix in a single forward. Similar to speculative decoding, we can guarantee at least one token to be accepted in each forward pass but TiDAR can accept much more tokens due to its superior drafting ability. 
            <!-- Plus, we guarantee one token per forward pass, similar to speculative decoding but with more added advantages.  -->
            Given the right draft length, we can maximally leverage the free token slots and achieve great decoding speedup from exceptionally high acceptance rate. 
            </p>
          </div>
        </div>

        <div class="content">
          <h3 class="title is-4" style="margin-bottom: 0.75rem; color:forestgreen;">Why is TiDAR special?</h3></li>
          <figure class="image">
            <img src="static/images/benchmark_throughput_barplot_ncg.png" style="width: 90%; height: auto;" alt="Why is TiDAR special?">
            <figcaption>
            Figure 4: TiDAR 8B decoding speed on SGLang using a single H100. 
            TiDAR achieves up to 5.8x higher decoding T/s than AR and 2.5x+ higher than EAGLE-v3.
          </figcaption>
          </figure>
          <div class="content has-text-justified">
            <ul>
              <li>
              TiDAR achieves the best inference latency under small batch sizes (better than SOTA speculative decoding such as <a href="https://arxiv.org/abs/2503.01840" target="_blank">EAGLE-v3</a>). 
              </li>
              <li>
              TiDAR significantly outperforms the quality-efficiency trade-offs than open-source DLMs such as <a href="https://arxiv.org/pdf/2508.15487" target="_blank">Dream</a> and <a href="https://arxiv.org/abs/2502.09992" target="_blank">Llada</a>.
              </li>
              <li>
              TiDAR is a standalone model that is easy to train and deploy with minimal hyperparameters to tune and low serving overhead.
              </li>
              <li>
              Training TiDAR is straightforward and data-efficient, with the dual objective of diffusion (Mask Token Prediction) and autoregression (Next Token Prediction), resulting in richer training signals than both traditional AR and Diffusion models.
              </li>
            </ul>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-fullwidth">
    <div class="columns is-centered has-text-centered">
      <div class="column">
        <h2 class="title is-3">Main Results</h2>
        <h3 class="title is-4" style="margin-bottom: 0.75rem; color:forestgreen;">Quality-Efficiency Trade-offs</h3></li>
        <div class="content has-text-justified mt-4">
          <figure class="image">
            <img src="static/images/efficiency-quality.png" alt="Quality-Efficiency Trade-offs" style="width: 80%; height: auto; object-fit: contain;">
          </figure>
          <p>
          TiDAR achieves impressive speedup over traditional AR models, and stays impressively competitive to SOTA speculative decoding method, EAGLE-v3, giving a wall-clock token per second throughput boost from 4.71x to 5.91x with PyTorch + Flex Attention implementation. 
          </p>
        </div>

        <h3 class="title is-4" style="margin-bottom: 0.75rem; color:forestgreen;">Likelihood & Generative Performance</h3></li>
        <div class="content has-text-justified mt-4">
          <br>
          <div class="columns is-vcentered is-variable is-1">
            <div class="column is-half">
              <figure class="image" style="margin: 0;">
                <img src="static/images/generative.png" alt="Generative" style="width: 100%; height: auto; object-fit: contain;">
              </figure>
            </div>
            <div class="column is-half">
              <figure class="image" style="margin: 0;">
                <img src="static/images/likelihood.png" alt="Likelihood" style="width: 100%; height: auto; object-fit: contain;">
              </figure>
            </div>
          </div>
          <p>
          We compare TiDAR with AR models (Llama, SmolLM, Qwen) and diffusion models (Dream, Llada, Block Diffusion) on downstream tasks.
          With only continual pretraining, not only does TiDAR outperform diffusion models (with the best quality at 1T/NFE) but also matches or significantly closes the gap to AR models. 
          </p>
        </div>

        <h3 class="title is-4" style="margin-bottom: 0.75rem; color:forestgreen;">Ablation Studies</h3></li>
        <div class="content has-text-justified">
          In our paper, we also conducted detailed ablation studies to better understand the design choices: 
          <ul>
            <li>
            Pareto Frontier under the same training recipe. 
            </li>
            <li>
            Comparing TiDAR's parallel decoding with other popular diffusion denoising strategies (such as threshold-based and left-to-right). 
            </li>
            <li>
            TiDAR gives the flexibility to verify with either AR or diffusion (or a mixture of both) predictions, and we showcase their effects on downstream performance. 
            </li>
            <li>
            One of the critical advantages of TiDAR is that we use one-step diffusion for efficient drafting. 
            To this end, we apply a simple full masking strategy to bridge train-test consistency and improve loss signal density. 
            </li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</section>


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
        @misc{liu2025tidarthinkdiffusiontalk,
          title={TiDAR: Think in Diffusion, Talk in Autoregression}, 
          author={Jingyu Liu and Xin Dong and Zhifan Ye and Rishabh Mehta and Yonggan Fu and Vartika Singh and Jan Kautz and Ce Zhang and Pavlo Molchanov},
          year={2025},
          eprint={2511.08923},
          archivePrefix={arXiv},
          primaryClass={cs.CL},
          url={https://arxiv.org/abs/2511.08923}, 
        }
      </code></pre>
    </div>
</section>
<!--End BibTex citation -->

  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

          <div class="policy-links has-text-centered">
            <a href="https://www.nvidia.com/en-us/about-nvidia/privacy-policy/" target="_blank" rel="noopener" class="policy-link">Privacy Policy</a>
            <span class="separator">‚Ä¢</span>
            <a href="https://www.nvidia.com/en-us/privacy-center/" target="_blank" rel="noopener" class="policy-link">Manage My Privacy</a>
            <span class="separator">‚Ä¢</span>
            <a href="https://www.nvidia.com/en-us/preferences/email-preferences/" target="_blank" rel="noopener" class="policy-link">Do Not Sell or Share My Data</a>
            <span class="separator">‚Ä¢</span>
            <a href="https://www.nvidia.com/en-us/about-nvidia/terms-of-service/" target="_blank" rel="noopener" class="policy-link">Terms of Service</a>
            <span class="separator">‚Ä¢</span>
            <a href="https://www.nvidia.com/en-us/about-nvidia/accessibility/" target="_blank" rel="noopener" class="policy-link">Accessibility</a>
            <span class="separator">‚Ä¢</span>
            <a href="https://www.nvidia.com/en-us/about-nvidia/company-policies/" target="_blank" rel="noopener" class="policy-link">Corporate Policies</a>
            <span class="separator">‚Ä¢</span>
            <a href="https://www.nvidia.com/en-us/contact/" target="_blank" rel="noopener" class="policy-link">Contact</a>
          </div>

        </div>
      </div>
    </div>
  </div>
</footer>

  </body>
  </html>
